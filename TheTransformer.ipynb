{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TheTransformer.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JHq-qg3q5WvK","colab_type":"text"},"source":["## Set Up"]},{"cell_type":"code","metadata":{"id":"czQEPNLS5PcC","colab_type":"code","outputId":"eb7c2926-70da-4e7e-cd95-3fa2b399706b","executionInfo":{"status":"ok","timestamp":1559806559652,"user_tz":-480,"elapsed":3282,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# connect to google drive\n","import os\n","import numpy as np\n","\n","# mount google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sCF-IioQ5PfA","colab_type":"code","outputId":"186657b1-9055-48e3-b8ac-8432d8bc83fa","executionInfo":{"status":"ok","timestamp":1559806566033,"user_tz":-480,"elapsed":4077,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# Check for GPU free memory\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","#!pip install psutil\n","#!pip install humanize\n","import psutil\n","import humanize\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","  process = psutil.Process(os.getpid())\n","  print('='*40)\n","  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","  print('='*40)\n","printm() "],"execution_count":98,"outputs":[{"output_type":"stream","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","The folder you are executing pip from can no longer be found.\n","========================================\n","Gen RAM Free: 9.8 GB  | Proc size: 5.2 GB\n","GPU RAM Free: 10554MB | Used: 4525MB | Util  30% | Total 15079MB\n","========================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5rfT5inl5Phn","colab_type":"code","outputId":"bd623342-eee2-4925-80c0-2e163c216a01","executionInfo":{"status":"ok","timestamp":1559806577466,"user_tz":-480,"elapsed":2344,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["# change root directory such that models are saved in google drive during training\n","root_dir = \"/content/gdrive/My Drive/NLP/MT_ENSP\"\n","os.chdir(root_dir)\n","!ls"],"execution_count":99,"outputs":[{"output_type":"stream","text":["code_utils\t\t   NMT_model\t\t      sanity_check_en_es_data\n","collect_submission.sh\t   NMT_model_mul_atten\t      sanity_check.py\n","Debugging.ipynb\t\t   NMT_model_mul_atten.optim  Tensor_file.log\n","en_es_data\t\t   NMT_model.optim\t      test_output.txt\n","gpu_requirements.txt\t   nmt_model.py\t\t      TheTransformer.ipynb\n","__init__.py\t\t   __pycache__\t\t      utils.py\n","local_env.yml\t\t   README.md\t\t      vocab.json\n","Machine_Translation.ipynb  run.py\t\t      vocab.py\n","model_embeddings.py\t   run.sh\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EJyNpjHJ52iW","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"t9_nkLJO5PkS","colab_type":"code","colab":{}},"source":["# insert the path for utility custom functions\n","import sys\n","sys.path.insert(0, os.path.join(root_dir, 'code_utils'))\n","\n","# custom python functions and classes\n","from utils import read_corpus, batch_iter, pad_sents\n","from vocab import Vocab, VocabEntry"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-gx4MW45Pmq","colab_type":"code","colab":{}},"source":["# basic packages\n","import math\n","import time\n","import copy\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn\n","\n","seaborn.set_context(context=\"talk\")\n","%matplotlib inline\n","\n","\n","from collections import Counter, namedtuple\n","from docopt import docopt\n","from itertools import chain\n","import json\n","from typing import List, Tuple, Dict, Set, Union\n","from docopt import docopt\n","\n","#pytorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.utils\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from torch.autograd import Variable\n","\n","\n","\n","#others\n","from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n","from tqdm import tqdm\n","from IPython.core.debugger import set_trace"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIupZjwr5PpR","colab_type":"code","colab":{}},"source":["# Logger\n","\n","import logging\n","logger = logging.getLogger(\"tensor_tracker\")\n","\n","file_handler = logging.FileHandler(\"Tensor_file.log\")\n","stream_handler = logging.StreamHandler()\n","formatter = logging.Formatter('%(message)s')\n","\n","file_handler.setFormatter(formatter)\n","stream_handler.setFormatter(formatter)\n","\n","logger.addHandler(file_handler)\n","\n","#logger.addHandler(stream_handler)\n","\n","logger.setLevel(logging.DEBUG)\n","\n","# A helper function to check how tensor sizes change\n","def log_size(tsr: torch.Tensor, name: str):\n","    #cls = getclass()\n","    logger.debug(msg=f\"{name} ==> size={tsr.shape}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XysvcBRO6kDl","colab_type":"text"},"source":["## Load data and EDA"]},{"cell_type":"code","metadata":{"id":"7uHesu0Y5PsB","colab_type":"code","outputId":"f0f221fb-bf49-4f97-d88f-100691159677","executionInfo":{"status":"ok","timestamp":1559806595233,"user_tz":-480,"elapsed":5434,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":638}},"source":["# load data\n","train_es = 'en_es_data/train.es'\n","train_en = 'en_es_data/train.en'\n","\n","dev_es = 'en_es_data/dev.es'\n","dev_en = 'en_es_data/dev.en'\n","\n","test_es = 'en_es_data/test.es'\n","test_en = 'en_es_data/test.en'\n","\n","\n","train_data_src = read_corpus(train_es, source='src')\n","train_data_tgt = read_corpus(train_en, source='tgt')\n","\n","dev_data_src = read_corpus(dev_es, source='src')\n","dev_data_tgt = read_corpus(dev_en, source='tgt')\n","\n","test_data_src = read_corpus(test_es, source='src')\n","test_data_tgt = read_corpus(test_en, source='tgt')\n","\n","train_data = list(zip(train_data_src,train_data_tgt))\n","dev_data = list(zip(dev_data_src,dev_data_tgt))\n","test_data = list(zip(test_data_src,test_data_tgt))\n","\n","#\n","print(\"==\"*40)\n","print(\"Number of examples in train: {}\".format(len(train_data)))\n","print(\"Number of examples in valid: {}\".format(len(dev_data)))\n","print(\"Number of examples in test: {}\".format(len(test_data)))\n","#\n","print(\"==\"*40)\n","print(\"Spanish --> English\")\n","es, en = next(iter(dev_data))\n","print(\"Sp: {}\".format(' '.join(es)))\n","print(\"En: {}\".format(' '.join(en)))\n","print(\"==\"*40)\n","\n","\n","## Build Vocab\n","# Build Vocab with train set\n","\n","size = 50000\n","freq_cutoff= 2\n","vocab_file = 'en_es_data/vocab.json'\n","\n","vocab = Vocab.build(train_data_src, train_data_tgt, size, freq_cutoff)\n","print('generated vocabulary, source %d words, target %d words' % (len(vocab.src), len(vocab.tgt)))\n","\n","vocab.save(vocab_file)\n","print('vocabulary saved to %s' % vocab_file)\n","\n","#\n","print(\"==\"*40)\n","print('Note that the <s> and </s> tokens are added while vocab\\\n","      initialization.\\nThese tokens are also present in target\\\n","      top frequent words. \\nThat is why vocab size for target language is lesser by 2.')\n","print(\"==\"*40)\n","\n","\n","# Check tokenization process\n","print(\"==\"*40)\n","sents = [['I', 'asgjsssd', 'will', 'be', 'there', 'for', 'you.'], ['This', 'is', 'spartaaaaaaaa.']]\n","print(\"Tokenize:\\n {} \\n {}\\n\".format(' '.join(sents[0]), ' '.join(sents[1])))\n","\n","print(vocab.tgt.to_input_tensor(sents, \"cpu\"))\n","#\n","print(\"==\"*40)\n","print(\"Note that 3 and 0  are <unk> and <pad> tokens!\")\n","print(\"==\"*40)"],"execution_count":103,"outputs":[{"output_type":"stream","text":["================================================================================\n","Number of examples in train: 216617\n","Number of examples in valid: 851\n","Number of examples in test: 8064\n","================================================================================\n","Spanish --> English\n","Sp: El ao pasado proyect estas dos diapositivas para demostrar que la capa de hielo rtico, que durante los ltimos tres millones de aos ha sido del tamao de los 48 estados, se ha reducido en un 40 por ciento.\n","En: <s> Last year I showed these two slides so that  demonstrate that the arctic ice cap,  which for most of the last three million years  has been the size of the lower 48 states,  has shrunk by 40 percent. </s>\n","================================================================================\n","initialize source vocabulary ..\n","number of word types: 172418, number of word types w/ frequency >= 2: 80623\n","initialize target vocabulary ..\n","number of word types: 128873, number of word types w/ frequency >= 2: 64215\n","generated vocabulary, source 50004 words, target 50002 words\n","vocabulary saved to en_es_data/vocab.json\n","================================================================================\n","Note that the <s> and </s> tokens are added while vocab      initialization.\n","These tokens are also present in target      top frequent words. \n","That is why vocab size for target language is lesser by 2.\n","================================================================================\n","================================================================================\n","Tokenize:\n"," I asgjsssd will be there for you. \n"," This is spartaaaaaaaa.\n","\n","tensor([[ 11,  76],\n","        [  3,  12],\n","        [ 88,   3],\n","        [ 29,   0],\n","        [ 67,   0],\n","        [ 19,   0],\n","        [165,   0]])\n","================================================================================\n","Note that 3 and 0  are <unk> and <pad> tokens!\n","================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ViwmqfYm6uHg","colab_type":"text"},"source":["## Develop"]},{"cell_type":"markdown","metadata":{"id":"8QxzgnCsAIUC","colab_type":"text"},"source":["### Scaled dot product attention"]},{"cell_type":"code","metadata":{"id":"-GUWoqEo5Pus","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","  \"\"\"Compute attention vectors for each time step\"\"\"\n","  def __init__(self, dropout_rate = 0.1):\n","    super(Attention, self).__init__()\n","    self.dropout = nn.Dropout(dropout_rate)\n","    \n","  def forward(self, Q, K, V, mask = None):\n","    \"\"\" Compute attention at each seq position in a batch\n","    @ param Q:  Tensor(batch, seq_len_1, d_k)\n","    @ param K:  Tensor(batch, seq_len_2, d_k)\n","    @ param V:  Tensor(batch, seq_len_2, d_v)\n","    @ param mask: Tensor(batch, 1, seq_len_2) or None: contains 0 at the location of pad/mask\n","    @ returns attn_vec: Tensor(batch, seq_len_2, d_v): weighted attention values at each seq location \n","    \"\"\"\n","    d_k = K.size(-1) # dimension of query and key\n","    assert Q.size(-1) == d_k, \"Query and Key dimensions must be same\"\n","    \n","    # compute dot product between queeries and keys for each batch and position \n","    # attn (b, i, j): how much (self) attention the query at seq location i should pay to key, value at seq location j for observation b\n","    attn = torch.bmm(Q,K.transpose(-2,-1)) #(batch, seq_len_1, d_k) * (batch, d_k, seq_len_2) : (batch, seq_len_1, seq_len_2) \n","    \n","    # Fill attention weight with large negative value where padding (or mask) is used: attn score will be ~ 0 for pad after softmax\n","    # set_trace()\n","    if mask is not None:\n","      #mask = mask.unsqueeze(dim=-2)\n","      attn = attn.masked_fill(mask == 0, -1e9)\n","      #set_trace()\n","      \n","    ## NB: masked_fill ==> fills elements of self tensor with value where mask is one. \n","    ##The shape of mask must be broadcastable with the shape of the underlying tensor.\n","    \n","    # normalize the att by sqrt(d_k): for better scaling of values as d_k bocomes large, \n","    ##else large activation values would be in small gradient range of softmax \n","    attn = attn/math.sqrt(d_k)\n","    \n","    # Allpy softmax along last dim i.e normalize the attn values for each query location\n","    attn = F.softmax(attn, dim = -1)\n","    \n","    # Apply dropout (during train)\n","    attn = self.dropout(attn)\n","    \n","    # Compute self attn vector using attn and values \n","    attn_vec = torch.bmm(attn, V) # (batch, seq_len_1, seq_len_2) * (batch, seq_len_2, d_v) : (batch, seq_len_1, d_v)\n","    \n","    return attn_vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bAmeIA25PxV","colab_type":"code","outputId":"b519d071-a799-4558-f3ee-f1d9389f3d4d","executionInfo":{"status":"ok","timestamp":1559806609328,"user_tz":-480,"elapsed":732,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_mech = Attention()\n","\n","batch, seq_len, d_k, d_v = 16, 5, 256, 512\n","Q = torch.rand(batch, seq_len, d_k)\n","K = torch.rand(batch, seq_len, d_k)\n","V = torch.rand(batch, seq_len, d_v)\n","\n","#mask = torch.tensor(np.zeros((batch,seq_len))) # mask everything\n","#mask[:,0] = 1\n","\n","attn_vec = attn_mech(Q,K,V)\n","print('shape = {}'.format(attn_vec.shape)) #(batch, seq_len, d_v) \n"],"execution_count":105,"outputs":[{"output_type":"stream","text":["shape = torch.Size([16, 5, 512])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cO9x8CW5R2rj","colab_type":"text"},"source":["### Attention Head"]},{"cell_type":"code","metadata":{"id":"tPL_o_dZR6WO","colab_type":"code","colab":{}},"source":["class AttentionHead(nn.Module):\n","  def __init__(self, d_model, d_k, d_v, dropout_rate = 0.1):\n","    super(AttentionHead, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_k = d_k\n","    self.d_v = d_v\n","    # Layers\n","    self.Q_proj = nn.Linear(d_model, d_k)\n","    self.K_proj = nn.Linear(d_model, d_k)\n","    self.V_proj = nn.Linear(d_model, d_v) # Note: d_k = d_v will be used \n","    self.attn = Attention(dropout_rate)\n","    \n","  def forward(self, Q_model, K_model, V_model, mask = None):\n","    \"\"\" Project model queries, keys, and values into a sub space and computes attention vectors\n","    param Q_model: Tensor(batch, seq_len, d_model)\n","    param K_model: Tensor(batch, seq_len, d_model)\n","    param V_model: Tensor(batch, seq_len, d_model)\n","    param mask: Tensor(batch, seq_len) or None: contains 0 at the location of pad/mask\n","    returns attn_vec: Tensor(batch, seq_len, d_feature)\n","    \"\"\"\n","    \n","    Q = self.Q_proj(Q_model)\n","    K = self.K_proj(K_model) \n","    V = self.V_proj(V_model)\n","    \n","    attn_vec = self.attn(Q,K,V, mask) #(batch, seq_len, d_v)\n","    \n","    return attn_vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPJqLsFSR6Yf","colab_type":"code","outputId":"b9987d7f-b4e2-47c7-f81d-308a69f0c7eb","executionInfo":{"status":"ok","timestamp":1559806614733,"user_tz":-480,"elapsed":733,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# basic sanity check\n","batch, seq_len, d_model, d_k, d_v = 16, 5, 64, 8, 24\n","\n","Q_model = torch.rand(batch, seq_len, d_model)\n","K_model = torch.rand(batch, seq_len, d_model)\n","V_model = torch.rand(batch, seq_len, d_model)\n","\n","head = AttentionHead(d_model,d_k, d_v)\n","\n","attn_vec = head(Q_model,K_model,V_model)\n","attn_vec.shape #(batch, seq_len, d_v)"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 5, 24])"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"markdown","metadata":{"id":"zI-DEY97Nykj","colab_type":"text"},"source":["### Multi-Head Attention"]},{"cell_type":"code","metadata":{"id":"bkdlKx-P5Pz6","colab_type":"code","colab":{}},"source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, n_head, d_model, dropout_rate = 0.1):\n","    super(MultiHeadAttention, self).__init__()\n","    \n","    # attributes\n","    assert d_model % n_head == 0, \"No of attention heads need to be a factor of model dimension\"\n","    self.n_head = n_head\n","    self.d_model = d_model # model dimensions\n","    self.d_k =  d_model // n_head\n","    self.d_v = self.d_k # edit this if dim(value) != dim(key)\n","    \n","    # layers\n","    self.attn_heads = nn.ModuleList([AttentionHead(self.d_model, self.d_k, self.d_v, dropout_rate) for i in range(n_head)])\n","    \n","    self.projection = nn.Linear(self.n_head*self.d_v, d_model)\n","    \n","  def forward(self, Q_model, K_model, V_model, mask=None):\n","    \n","    \"\"\" Perform multi-headed attention on model query, key, value\n","    param Q_model: Tensor (batch, seq_len, d_model)\n","    param K_model: Tensor (batch, seq_len, d_model)\n","    param V_model: Tensor (batch, seq_len, d_model)\n","    returns X: Tensor(batch, seq_len, d_model) : self-attention values at each position of sequence\n","    \"\"\"\n","    \n","    values = [attn_head(Q_model, K_model, V_model, mask) for i, attn_head in enumerate(self.attn_heads)] \n","    # list containing nHead tensors of shape (batch, seq_len, d_v)\n","    \n","    X = torch.cat(values, dim = -1) # (batch, seq_len, nHead*d_v)\n","    X = self.projection(X) #(batch, seq_len, d_model)\n","    \n","    return X\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5WVn9x35P2y","colab_type":"code","outputId":"b415e39a-c15c-4d51-a4df-3f779a3c7d80","executionInfo":{"status":"ok","timestamp":1559806620620,"user_tz":-480,"elapsed":757,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# basic sanity check\n","batch, seq_len, d_model, n_head = 16, 5, 64, 8\n","\n","Q_model = torch.rand(batch, seq_len, d_model)\n","K_model = torch.rand(batch, seq_len, d_model)\n","V_model = torch.rand(batch, seq_len, d_model)\n","\n","multi_head = MultiHeadAttention(n_head, d_model)\n","\n","attn_vec = multi_head(Q_model,K_model,V_model)\n","attn_vec.shape #(batch, seq_len, d_model)"],"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 5, 64])"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"code","metadata":{"id":"yXWwN4vY5P5n","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJoMMBeqtn6O","colab_type":"text"},"source":["### Feed Forward"]},{"cell_type":"code","metadata":{"id":"51tYb1zy5P8Q","colab_type":"code","colab":{}},"source":["class FeedForward(nn.Module):\n","  def __init__(self, d_model, d_hidden, dropout_rate = 0.1):\n","    super(FeedForward, self).__init__()\n","    \n","    # layers\n","    self.ff1 = nn.Linear(d_model, d_hidden)\n","    self.ff2 = nn.Linear(d_hidden, d_model)\n","    self.dropout = nn.Dropout(dropout_rate)\n","    \n","  def forward(self, x):\n","    \"\"\" Position wise feed forward with two linear layers\n","    @ param x: Tensor (batch, d_model): attention value output \n","    @ return out: Tensor(batch,d_model)\n","    \"\"\"\n","    x = F.relu(self.ff1(x))\n","    out = self.ff2(self.dropout(x))\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kb3jBZLOvtud","colab_type":"text"},"source":["### Layer Norm"]},{"cell_type":"code","metadata":{"id":"CtX7mXht5P-6","colab_type":"code","colab":{}},"source":["class LayerNorm(nn.Module):\n","  def __init__(self, d_model, eps =1e-6):\n","    super(LayerNorm, self).__init__()\n","    \n","    # attributes\n","    self.beta = nn.Parameter(torch.zeros(d_model)) # mean of transformed features\n","    self.gamma = nn.Parameter(torch.ones(d_model)) # sd\n","    self.eps = eps\n","     \n","  def forward(self,x):\n","    \"\"\" returns layer norm\n","    @ param x: Tensor (batch, d_model)\n","    @ returns x_tf : Tensor (batch,d_model)\n","    \"\"\"\n","    mean = x.mean(-1, keepdim = True) #(batch,1)\n","    std = x.std(-1, keepdim = True)   #(batch,1)\n","    x_tf = self.gamma*(x-mean)/(std+self.eps) + self.beta #[(d_model)]*[(batch,d_model) - (batch,1)]/(batch,1) + [(d_model)]\n","    return x_tf\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpKzz1XJ1I5p","colab_type":"code","outputId":"3b7ce09d-9f7f-4291-f487-497074f2dd64","executionInfo":{"status":"ok","timestamp":1559806629414,"user_tz":-480,"elapsed":837,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# basic sanity check\n","d_model = 256\n","batch = 16\n","x = torch.zeros(batch,d_model)\n","layerNorm = LayerNorm(d_model)\n","x_tr = layerNorm(x)\n","x_tr.shape"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 256])"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"tDlEEfRS1zHa","colab_type":"text"},"source":["###  Embeddings"]},{"cell_type":"code","metadata":{"id":"ZXmE_lMb1267","colab_type":"code","colab":{}},"source":["class Embeddings(nn.Module):\n","  \n","  def __init__(self, vocab_size, d_model, pad_index= None):\n","    super(Embeddings, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.vocab_size = vocab_size\n","    #layer\n","    self.LUT = nn.Embedding(vocab_size, d_model, padding_idx = pad_index)\n","    \n","  def forward(self, x):\n","    \"\"\" Get the embedding for x\n","    @ param x: tokes (batch, seq_len)\n","    @ return x_embed (batch, seq_len, x_embed)\n","    \"\"\"\n","    x_embed = self.LUT(x)*math.sqrt(self.d_model)\n","    return x_embed\n","  \n","## Positional encoding\n","class PositionalEncoding(nn.Module):\n","  \n","  def __init__(self, d_model, max_len = 1024):\n","    super(PositionalEncoding, self).__init__()\n","    #self.d_model = d_model\n","    #set_trace()\n","    \n","    pe = torch.zeros(max_len, d_model)\n","    position = torch.arange(0,max_len).unsqueeze(dim=1).float() #(max_len,1)\n","    div_term = torch.exp(-torch.arange(0, d_model, 2).float() * (math.log(10000.0) / d_model))\n","    \n","    pe[:, 0::2] = torch.sin(position * div_term)\n","    pe[:, 1::2] = torch.cos(position * div_term)\n","    \n","    pe = pe.unsqueeze(0) #(1,max_len,d_model)\n","    # unsqueezed at dim 0 to enable broadcasting along batch dimension\n","    self.weight = nn.Parameter(pe, requires_grad=False)\n","    \n","  def forward(self, x):\n","    \"\"\" Returns positional encoding for a input sequence \n","    @ param x: Tensor (batch, seq_len)\n","    @ returns positional encoding of shape (batch, seq_len, d_model)\n","    \"\"\"\n","    return self.weight[:, :x.size(1), :] # (1, seq_len, d_model) \n","  \n","  \n","## Final embeddings\n","class NetEmbedding(nn.Module):\n","  def __init__(self, vocab_size, d_model, pad_index = None, dropout_rate = 0.1):\n","    super(NetEmbedding, self).__init__()\n","\n","    # layers\n","    self.reg_embed = Embeddings(vocab_size, d_model, pad_index)\n","    self.pos_embed = PositionalEncoding(d_model)\n","    self.dropout = nn.Dropout(dropout_rate)\n","\n","  def forward(self,x):\n","    \"\"\" Final embeddings for a input sequence\n","    @ param x: input sequence Tensor (batch, seq_len)\n","    @ returns x_next : corresponding net embeddings (batch, seq_len, d_model)\n","    \"\"\"\n","    #set_trace()\n","    x_net = self.reg_embed(x) + self.pos_embed(x) #(batch,seq_len,d_model) + (1,seq_len,d_model)\n","    return self.dropout(x_net)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2i807td_WY_","colab_type":"code","outputId":"0d0ef67f-a5e1-49db-9eba-85ac43683e28","executionInfo":{"status":"ok","timestamp":1559806635391,"user_tz":-480,"elapsed":1019,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["get_embed = NetEmbedding(50000,512)\n","x = torch.tensor([np.arange(5), np.arange(5)])\n","x_embed = get_embed(x)\n","x_embed.dtype"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"id":"MSSVWHvj13B_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BnwVBsD5qbwJ","colab_type":"text"},"source":["### Residual Connection"]},{"cell_type":"code","metadata":{"id":"qWqROVNOqgPY","colab_type":"code","colab":{}},"source":["class ResConnect(nn.Module):\n","  \n","  def __init__(self, d_model, dropout_rate=0.1):\n","    super(ResConnect, self).__init__()\n","    self.layer_norm = LayerNorm(d_model)\n","    self.dropout = nn.Dropout(dropout_rate)\n","    \n","  def forward(self, x, x_mapped):\n","    x_out = x + self.dropout(self.layer_norm(x_mapped))\n","    return x_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-tRD0ewqgRr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVAnNm79qgUM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXWctAbHwlc9","colab_type":"text"},"source":["### One Encoder Block"]},{"cell_type":"code","metadata":{"id":"kU1Qt-8L5QBv","colab_type":"code","colab":{}},"source":["class EncoderBlock(nn.Module):\n","  \n","  def __init__(self, n_head =8, d_model=512, d_hidden=2084, dropout_rate = 0.1):\n","    \n","    super(EncoderBlock, self).__init__()\n","    \n","    self.attn_head = MultiHeadAttention(n_head, d_model, dropout_rate)\n","    self.connect_1 = ResConnect(d_model, dropout_rate)\n","    self.connect_2 = ResConnect(d_model, dropout_rate)\n","    self.dropout = nn.Dropout(dropout_rate)\n","    self.feedforward = FeedForward(d_model, d_hidden, dropout_rate)\n","    \n","  def forward(self, x, mask= None):\n","    \"\"\"\n","    One encoder block which will be cloned N times for total encoder block\n","    @ param x: Tensor(batch, seq_len, d_model)\n","    @ param mask: Tensor (batch, 1, seq_len)\n","    @ returns encoded x_out with self attention and feed forward\n","    \"\"\"\n","    attn = self.attn_head(x, x, x, mask=mask) #(batch, seq_len, d_model)\n","    \n","    # Apply first normalization and residual connection\n","    x = self.connect_1(x, attn)\n","    \n","    # point-wise feed forward\n","    x_ff = self.feedforward(x)\n","    \n","    # apply second normalization and residual connection\n","    x_out = self.connect_2(x, x_ff)\n","    \n","    return x_out\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aw9yN5cn5QD-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBwRXEZoQWS6","colab_type":"text"},"source":["## Encoder"]},{"cell_type":"code","metadata":{"id":"y4Y8RTXZQVWp","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","  \n","  def __init__(self, n_blocks = 6, n_head = 8, d_model = 512, d_hidden = 2048, dropout_rate = 0.1):\n","    super(Encoder, self).__init__()\n","    \n","    #self.n_blocks = n_blocks\n","    self.encoders = nn.ModuleList([EncoderBlock(n_head,d_model,d_hidden,dropout_rate) for i in range(n_blocks)])\n","    self.layernorm = LayerNorm(d_model)\n","    \n","  def forward(self, x, mask=None):\n","    \n","    \"\"\" The Encoder module\n","    @ param x: Tensor(batch, seq_len, d_model)\n","    @ param mask: Tensor(batch, 1, seq_len) with zeros at loacations of padding or intended mask\n","    @ returns encoded x to be used for decoding: Tensor(batch, seq_len, d_model)\n","    \"\"\"\n","    for encoder in self.encoders:\n","      x = encoder(x, mask)\n","      \n","    return self.layernorm(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mJG0NbjSTtT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BA_bHnixwoZ0","colab_type":"text"},"source":["### Decoder Block"]},{"cell_type":"code","metadata":{"id":"SifPX6AU5QGA","colab_type":"code","colab":{}},"source":["class DecoderBlock(nn.Module):\n","  \n","  def __init__(self, n_head =8, d_model=512, d_hidden=2084, dropout_rate = 0.1):\n","    super(DecoderBlock, self).__init__()\n","    \n","    self.masked_attn_head = MultiHeadAttention(n_head, d_model, dropout_rate) # decoder self-attention\n","    self.attn_head = MultiHeadAttention(n_head, d_model, dropout_rate) # encoder-decoder attention\n","    self.feedforward = FeedForward(d_model, d_hidden, dropout_rate)\n","    \n","    self.connect_1 = ResConnect(d_model, dropout_rate)\n","    self.connect_2 = ResConnect(d_model, dropout_rate)\n","    self.connect_3 = ResConnect(d_model, dropout_rate)\n","\n","    self.dropout = nn.Dropout(dropout_rate)\n","    \n","  def forward(self, x, enc_out, src_mask= None, tgt_mask = None):\n","    \"\"\" Decoder block to be cloned N times\n","    @ param x: decoded seq Tensor (batch, tgt_len, d_model)\n","    @ param enc_out: encoded input sequence of shape (batch, src_len, d_model)\n","    @ param src_mask: Tensor(batch, 1, src_len) with zero at padding token ??\n","    @ param tgt_mask: Tensor (batch, tgt_len, tgt_len) with zeros s.t. tgt_mask[:, i, i+1:] = 0\n","    @ returns decoded x of shape (batch, tgt_len, d_model)\n","    \"\"\"\n","    \n","    # Apply self-attention to decoder sequence with taget masking to prevent left side information flow\n","    attn = self.masked_attn_head(x, x, x, mask = tgt_mask)\n","    \n","    # Apply first residual connection    \n","    x = self.connect_1(x, attn)\n","    \n","    # Apply encoder-decoder attention\n","    attn = self.attn_head(Q_model = x, K_model = enc_out, V_model = enc_out, mask=src_mask)\n","    \n","    # Apply second residual connection\n","    x = self.connect_2(x, attn)\n","    \n","    # Apply position-wise feedforward network\n","    x_ff = self.feedforward(x)\n","    \n","    # Apply third residual connection\n","    x = self.connect_3(x, x_ff)\n","    \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyelOXHozquC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jmuUvgrrzrBm","colab_type":"text"},"source":["## Decoder"]},{"cell_type":"code","metadata":{"id":"hKq8CBaUwqN7","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","  \n","  def __init__(self, n_blocks = 6, n_head = 8, d_model = 512, d_hidden = 2048, dropout_rate = 0.1):\n","    super(Decoder, self).__init__()\n","    \n","    #self.n_blocks = n_blocks\n","    self.decoders = nn.ModuleList([DecoderBlock(n_head,d_model,d_hidden,dropout_rate) for i in range(n_blocks)])\n","    self.layernorm = LayerNorm(d_model)\n","    \n","  def forward(self, x, enc_out, src_mask = None, tgt_mask = None):\n","    \n","    \"\"\" The Encoder module\n","    @ param x: Tensor(batch, seq_len, d_model)\n","    @ param mask: Tensor(batch, 1, seq_len) with zeros at loacations of padding or intended mask\n","    @ returns encoded x to be used for decoding: Tensor(batch, seq_len, d_model)\n","    \"\"\"\n","    for decoder in self.decoders:\n","      x = decoder(x, enc_out, src_mask, tgt_mask)\n","      \n","    return self.layernorm(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHgAR9HUwqQV","colab_type":"code","colab":{}},"source":["## Function to create tgt_mask\n","def subsequent_mask(tgt_len):\n","    \"Mask out subsequent positions.\"\n","    attn_shape = (1, tgt_len, tgt_len)\n","    \n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8') # upper triangular matrix\n","    \n","    return torch.from_numpy(subsequent_mask) == 0 ## ByteTensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m703GPV41r3e","colab_type":"code","outputId":"428058ec-2cec-40a2-afd4-e965ae368795","executionInfo":{"status":"ok","timestamp":1559800091329,"user_tz":-480,"elapsed":779,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":342}},"source":["plt.figure(figsize=(5,5))\n","plt.imshow(subsequent_mask(20)[0])\n","None"],"execution_count":55,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAVgAAAFFCAYAAACpJPUFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SAj3w4gw1zSp","colab_type":"code","outputId":"d57eb296-dbfc-4806-b744-e16f273969e9","executionInfo":{"status":"ok","timestamp":1559806654789,"user_tz":-480,"elapsed":708,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mask = subsequent_mask(20)[0]\n","print(mask.dtype)"],"execution_count":121,"outputs":[{"output_type":"stream","text":["torch.uint8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CzFzfskP_X3w","colab_type":"text"},"source":["### Generator"]},{"cell_type":"code","metadata":{"id":"n1Cy88P__aIO","colab_type":"code","colab":{}},"source":["class Generator(nn.Module):\n","    \"Define standard linear + softmax generation step.\"\n","    def __init__(self, vocab_size, d_model):\n","        super(Generator, self).__init__()\n","        self.proj = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x):\n","        return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fj1PtV0B_aSt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ufsfyets0fSX","colab_type":"text"},"source":["## Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"ComPEGXJwqSp","colab_type":"code","colab":{}},"source":["class EncoderDecoder(nn.Module):\n","  \"\"\" Final model architecture \"\"\"\n","  def __init__(self, vocab, encoder, decoder, src_embed, tgt_embed, generator):\n","    super(EncoderDecoder, self).__init__()\n","    \n","    self.vocab = vocab\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.src_embed = src_embed\n","    self.tgt_embed = tgt_embed\n","    self.generator = generator\n","  \n","  def forward(self, source, target):\n","    \"\"\" Attention Is All You Need\n","    @ param src: source sentences List[List [str]]\n","    @ param tgt: target sentences List[List[str]]\n","    @ returns scores: a variable/tensor of shape (batch, ) representing the\n","      log-likelihood of generating the gold-standard target sentence \n","    \"\"\"\n","    \n","    source_padded = self.vocab.src.to_input_tensor(source, device=self.device)   # Tensor: (src_len, batch)\n","    target_padded = self.vocab.tgt.to_input_tensor(target, device=self.device)   # Tensor: (tgt_len, batch)\n","    \n","    #set_trace()\n","    \n","    src, tgt = source_padded.transpose(0,1), target_padded.transpose(0,1) # (batch, seq_len)\n","    tgt_in = tgt[:, :-1] # Chop of the <END> token for max length sentences.\n","    tgt_out = tgt[:, 1:] # Right Shift of target for prediction\n","    \n","    src_mask = self.generate_src_mask(src)\n","    tgt_mask_in = self.generate_tgt_mask(tgt_in)\n","    \n","    enc_out = self.encode(src, src_mask)\n","    dec_out = self.decode(enc_out, src_mask, tgt_in, tgt_mask_in) #(batch, tgt_len, d_model)\n","    pred_sents = self.generator(dec_out) #(batch, tgt_len, tgt_vocab_size)\n","    \n","    P = F.log_softmax(pred_sents, dim=-1) #(batch, tgt_len, tgt_vocab_size)\n","    # Zero out, probabilities for which we have nothing in the target text\n","    tgt_mask_out = (tgt_out != self.vocab.tgt['<pad>']).float() #(batch, tgt_len)\n","    \n","    # Compute log probability of generating true target words\n","    target_gold_words_log_prob = torch.gather(P, index= tgt_out.unsqueeze(-1), dim=-1).squeeze(-1) * tgt_mask_out #(batch, tgt_len)\n","    scores = target_gold_words_log_prob.sum(dim=-1)\n","    \n","    return scores\n","  \n","  \n","    \n","  def encode(self, src, src_mask):\n","    \"\"\" Encoder for source sentences \"\"\"\n","    \n","    x_embed = self.src_embed(src) # (batch, src_len, d_model)\n","    enc_out = self.encoder(x_embed, src_mask)\n","    return enc_out\n","  \n","  def decode(self, enc_out, src_mask, tgt, tgt_mask):\n","    \"\"\" Decoder for translation \"\"\"\n","    tgt_embed = self.tgt_embed(tgt)\n","    dec_out = self.decoder(tgt_embed, enc_out, src_mask, tgt_mask)\n","    return dec_out\n","  \n","  def generate_src_mask(self, src):\n","    \"\"\" create mask for source sentences \n","    @ param src: padded source sentences tensor of shape (batch, src_len)\n","    @ returns src_mask: Tensor(batch, 1, src_len)    \n","    \"\"\"\n","    pad_id = self.vocab.src['<pad>']\n","    src_mask = (src != pad_id).unsqueeze(-2)  #Tensor(batch, 1, src_len)\n","    \n","    return src_mask\n","  \n","  def generate_tgt_mask(self, tgt):\n","    \"\"\" create mask for source sentences \n","    @ param tgt: padded target sentences tensor of shape (batch, tgt_len)\n","    @ returns tgt_mask: Tensor(batch, tgt_len, tgt_len)    \n","    \"\"\"\n","    #set_trace()\n","    pad_id = self.vocab.tgt['<pad>']\n","    pad_mask = (tgt != pad_id).unsqueeze(-2)  #Tensor(batch, 1, tgt_len)\n","    \n","    tgt_len = tgt.size(-1)\n","    attn_shape = (1, tgt_len, tgt_len)\n","    \n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8') # upper triangular matrix\n","\n","    subsequent_mask = torch.tensor(subsequent_mask, device= self.device) == 0\n","    \n","    #subsequent_mask = torch.from_numpy(subsequent_mask) == 0 ## ByteTensor (1, tgt_len, tgt_len)\n","    \n","    tgt_mask = (pad_mask & subsequent_mask) #(batch, tgt_len, tgt_len)\n","    \n","    return tgt_mask\n","  \n","  \n","  @property\n","  def device(self):\n","    return self.src_embed.reg_embed.LUT.weight.device\n","  \n","  @staticmethod\n","  def load(model_path: str):\n","    \"\"\" Load the model from a file.\n","    @param model_path (str): path to model\n","    \"\"\"\n","    params = torch.load(model_path, map_location=lambda storage, loc: storage)\n","    args = params['args']\n","    model = NMT(vocab=params['vocab'], **args)\n","    model.load_state_dict(params['state_dict'])\n","\n","    return model\n","\n","  def save(self, path: str):\n","      \"\"\" Save the odel to a file.\n","      @param path (str): path to the model\n","      \"\"\"\n","      print('save model parameters to [%s]' % path, file=sys.stderr)\n","\n","      params = {\n","          'args': dict(dropout_rate=self.dropout_rate),\n","          'vocab': self.vocab,\n","          'state_dict': self.state_dict()\n","      }\n","\n","      torch.save(params, path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHzZlbT3wqZp","colab_type":"code","colab":{}},"source":["## Create model\n","def make_model(vocab, n_blocks=6, n_head=8, d_model=512, d_hidden=2048, dropout_rate = 0.1):\n","  \"\"\" Create the model\n","  @ vocab: Vocab object\n","  \"\"\"\n","  src_vocab = vocab.src # VocabEntry object\n","  src_vocab_size = len(src_vocab)\n","  src_pad_index = vocab.src['<pad>']\n","  \n","  tgt_vocab = vocab.tgt # VocabENtry object\n","  tgt_vocab_size = len(tgt_vocab)\n","  tgt_pad_index = vocab.tgt['<pad>']\n","  \n","  src_embed = NetEmbedding(src_vocab_size, d_model, src_pad_index, dropout_rate)\n","  tgt_embed = NetEmbedding(tgt_vocab_size, d_model, tgt_pad_index, dropout_rate)\n","  \n","  encoder = Encoder(n_blocks, n_head, d_model, d_hidden, dropout_rate)\n","  decoder = Decoder(n_blocks, n_head, d_model, d_hidden, dropout_rate)\n","  generator = Generator(tgt_vocab_size, d_model)\n","  \n","  model = EncoderDecoder(vocab, encoder, decoder, src_embed, tgt_embed, generator)\n","  \n","  # Initialization\n","  for p in model.parameters():\n","    if p.dim() > 1:\n","      nn.init.xavier_uniform_(p)\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5h7CRdRpwqd6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hocAu6byA2Tq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dt3nPW4DCBuj","colab_type":"text"},"source":["## Model functions"]},{"cell_type":"code","metadata":{"id":"8jm4gXkvA2WO","colab_type":"code","outputId":"b6b2927b-f3e2-48db-facd-18d78c643f5e","executionInfo":{"status":"ok","timestamp":1559806671577,"user_tz":-480,"elapsed":5530,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["# load data\n","train_es = 'en_es_data/train.es'\n","train_en = 'en_es_data/train.en'\n","\n","dev_es = 'en_es_data/dev.es'\n","dev_en = 'en_es_data/dev.en'\n","\n","test_es = 'en_es_data/test.es'\n","test_en = 'en_es_data/test.en'\n","\n","\n","train_data_src = read_corpus(train_es, source='src')\n","train_data_tgt = read_corpus(train_en, source='tgt')\n","\n","dev_data_src = read_corpus(dev_es, source='src')\n","dev_data_tgt = read_corpus(dev_en, source='tgt')\n","\n","test_data_src = read_corpus(test_es, source='src')\n","test_data_tgt = read_corpus(test_en, source='tgt')\n","\n","train_data = list(zip(train_data_src,train_data_tgt))\n","dev_data = list(zip(dev_data_src,dev_data_tgt))\n","test_data = list(zip(test_data_src,test_data_tgt))\n","\n","## Build Vocab\n","# Build Vocab with train set\n","\n","size = 50000\n","freq_cutoff= 2\n","vocab_file = 'en_es_data/vocab.json'\n","\n","vocab = Vocab.build(train_data_src, train_data_tgt, size, freq_cutoff)\n","print('generated vocabulary, source %d words, target %d words' % (len(vocab.src), len(vocab.tgt)))\n","\n","vocab.save(vocab_file)\n","print('vocabulary saved to %s' % vocab_file)\n"],"execution_count":125,"outputs":[{"output_type":"stream","text":["initialize source vocabulary ..\n","number of word types: 172418, number of word types w/ frequency >= 2: 80623\n","initialize target vocabulary ..\n","number of word types: 128873, number of word types w/ frequency >= 2: 64215\n","generated vocabulary, source 50004 words, target 50002 words\n","vocabulary saved to en_es_data/vocab.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7rFIliKDA2Yk","colab_type":"code","colab":{}},"source":["## Evaluation metric\n","def evaluate_ppl(model, dev_data, batch_size=32):\n","    \"\"\" Evaluate perplexity on dev sentences\n","    @param model (NMT): NMT_char Model\n","    @param dev_data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n","    @param batch_size (batch size)\n","    @returns ppl (perplixty on dev sentences)\n","    \"\"\"\n","    was_training = model.training\n","    model.eval()\n","\n","    cum_loss = 0.\n","    cum_tgt_words = 0.\n","\n","    # no_grad() signals backend to throw away all gradients\n","    with torch.no_grad():\n","        for src_sents, tgt_sents in batch_iter(dev_data, batch_size):\n","            loss = -model(src_sents, tgt_sents).sum()\n","\n","            cum_loss += loss.item()\n","            tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n","            cum_tgt_words += tgt_word_num_to_predict\n","\n","        ppl = np.exp(cum_loss / cum_tgt_words)\n","\n","    if was_training:\n","        model.train()\n","\n","    return ppl"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KgQ2sllQA2a9","colab_type":"code","colab":{}},"source":["## Train\n","\n","def train_model(model, optimizer, clip_grad =5.0, max_epoch =30, max_patience = 3, max_trial = 3, lr_decay = 0.5, train_batch_size = 64, log_every = 100, valid_niter = 1000):\n","  \n","  \n","  print('Training begins...')\n","  ## Temp variables\n","  num_trial = 0\n","  train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n","  cum_examples = report_examples  = valid_num = 0\n","  hist_valid_scores = []\n","  train_time = begin_time = time.time()\n","  \n","  # put the model in training mode\n","  model.train()\n","  \n","  # iterate over the epochs\n","  for epoch in range(max_epoch):\n","    for src_sents, tgt_sents in batch_iter(train_data, batch_size=train_batch_size, shuffle=True):\n","        \n","        train_iter += 1\n","        optimizer.zero_grad()\n","        batch_size = len(src_sents)\n","        \n","        example_losses = -model(src_sents, tgt_sents)\n","        batch_loss = example_losses.sum()\n","        loss = batch_loss/batch_size\n","        loss.backward() # autograd\n","        \n","        # Clip gradient\n","        grad_norn = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n","        optimizer.step() # update parameters\n","        \n","        batch_losses_val = batch_loss.item()\n","        report_loss += batch_losses_val\n","        cum_loss += batch_losses_val\n","        \n","        tgt_words_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n","        report_tgt_words += tgt_words_num_to_predict\n","        cum_tgt_words += tgt_words_num_to_predict\n","        report_examples += batch_size\n","        cum_examples += batch_size\n","        \n","        # print interim report about training\n","        \n","        if train_iter % log_every == 0:\n","            #set_trace()\n","            print('| Epoch %d, Iter %d| Avg Loss = %.2f| Avg. ppl = %.2f| Speed %.2f words/sec| Time %.2f min|' % (epoch+1, train_iter, report_loss / report_examples, math.exp(report_loss / report_tgt_words),\n","                                                                                     report_tgt_words / (time.time() - train_time), (time.time() - begin_time)/60.0))\n","\n","            train_time = time.time()\n","            report_loss = report_tgt_words = report_examples = 0.\n","        \n","        # validation\n","        if train_iter % valid_niter == 0:\n","            \n","            print('| <Train Summary> | Epoch %d, Iter %d| Cum. loss = %.2f| Cum. ppl = %.2f|' % (epoch+1, train_iter, cum_loss / cum_examples, np.exp(cum_loss / cum_tgt_words)))\n","\n","            cum_loss = cum_examples = cum_tgt_words = 0.\n","            valid_num += 1\n","\n","            print('Report on validation set:', file=sys.stderr)\n","\n","            # compute dev. ppl and bleu\n","            dev_ppl = evaluate_ppl(model, dev_data, batch_size=128)   # dev batch size can be a bit larger\n","            valid_metric = -dev_ppl\n","\n","            print('Validation:  Dev. ppl = %f' % (dev_ppl), file=sys.stderr)\n","\n","            \n","            # learning rate scheduling\n","            \n","            is_better = (len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores))\n","            hist_valid_scores.append(valid_metric)\n","\n","            if is_better:\n","                patience = 0\n","                print('Save currently the best model to [%s]' % model_save_path, file=sys.stderr)\n","                model.save(model_save_path)\n","\n","                # also save the optimizers' state\n","                torch.save(optimizer.state_dict(), model_save_path + '.optim')\n","                \n","            elif patience < int(max_patience):\n","                patience += 1\n","                print('Hit patience %d' % patience, file=sys.stderr)\n","\n","                if patience == int(max_patience):\n","                    num_trial += 1\n","                    print('Hit #%d trial' % num_trial, file=sys.stderr)\n","                    \n","                    if num_trial == int(max_trial):\n","                        print('early stop!', file=sys.stderr)\n","                        return\n","\n","                    # decay lr, and restore from previously best checkpoint\n","                    lr = optimizer.param_groups[0]['lr'] * float(lr_decay)\n","                    print('load previously best model and decay learning rate to %f' % lr, file=sys.stderr)\n","\n","                    # load model\n","                    params = torch.load(model_save_path, map_location=lambda storage, loc: storage)\n","                    model.load_state_dict(params['state_dict'])\n","                    model = model.to(device)\n","\n","                    print('restore parameters of the optimizers', file=sys.stderr)\n","                    optimizer.load_state_dict(torch.load(model_save_path + '.optim'))\n","\n","                    # set new lr\n","                    for param_group in optimizer.param_groups:\n","                        param_group['lr'] = lr\n","\n","                    # reset patience\n","                    patience = 0\n","\n","            if epoch +1 == int(max_epoch):\n","                print('Training stopped <-> Reached maximum number of epochs!', file=sys.stderr)\n","                return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1UvleWbA2gk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMQEsY3AA2jI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R9YWfoSyqDZ6","colab_type":"text"},"source":["## Training "]},{"cell_type":"code","metadata":{"id":"I8Qj-SoSA2mC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":654},"outputId":"d8664c7d-70a5-4b43-fb0b-3e79617a5aa7","executionInfo":{"status":"error","timestamp":1559807241029,"user_tz":-480,"elapsed":357233,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}}},"source":["# initialize the model\n","# model = NMT_char(embed_size= 256, hidden_size=256, dropout_rate=0.3, vocab=vocab)\n","model = make_model(vocab)\n","\n","# define model saving path\n","model_save_path = 'Transformer_model.pt'\n","\n","# transfer the model to cuda if available\n","device = torch.device(\"cuda:0\" if torch.cuda.device_count()>0 else \"cpu\")\n","print('Use device: %s' % device, file=sys.stderr)\n","model = model.to(device)\n","\n","# optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","\n","\n","# train parameters\n","max_epoch =30\n","train_batch_size = 16\n","\n","# train the model\n","train_model(model, optimizer, max_epoch =max_epoch, train_batch_size = train_batch_size)"],"execution_count":137,"outputs":[{"output_type":"stream","text":["Use device: cuda:0\n"],"name":"stderr"},{"output_type":"stream","text":["Training begins...\n","| Epoch 1, Iter 100| Avg Loss = 129.05| Avg. ppl = 1769.42| Speed 783.35 words/sec| Time 0.59 min|\n","| Epoch 1, Iter 200| Avg Loss = 119.88| Avg. ppl = 933.72| Speed 797.53 words/sec| Time 1.17 min|\n","| Epoch 1, Iter 300| Avg Loss = 117.11| Avg. ppl = 755.65| Speed 798.74 words/sec| Time 1.76 min|\n","| Epoch 1, Iter 400| Avg Loss = 119.72| Avg. ppl = 708.43| Speed 825.36 words/sec| Time 2.35 min|\n","| Epoch 1, Iter 500| Avg Loss = 118.01| Avg. ppl = 655.88| Speed 821.33 words/sec| Time 2.94 min|\n","| Epoch 1, Iter 600| Avg Loss = 113.79| Avg. ppl = 631.88| Speed 803.33 words/sec| Time 3.53 min|\n","| Epoch 1, Iter 700| Avg Loss = 111.98| Avg. ppl = 591.22| Speed 809.16 words/sec| Time 4.11 min|\n","| Epoch 1, Iter 800| Avg Loss = 112.35| Avg. ppl = 582.18| Speed 806.77 words/sec| Time 4.69 min|\n","| Epoch 1, Iter 900| Avg Loss = 110.23| Avg. ppl = 566.33| Speed 797.23 words/sec| Time 5.27 min|\n","| Epoch 1, Iter 1000| Avg Loss = 111.00| Avg. ppl = 549.75| Speed 801.99 words/sec| Time 5.86 min|\n","| <Train Summary> | Epoch 1, Iter 1000| Cum. loss = 116.31| Cum. ppl = 722.05|\n"],"name":"stdout"},{"output_type":"stream","text":["Report on validation set:\n","Validation:  Dev. ppl = 495.000719\n","Save currently the best model to [Transformer_model.pt]\n","save model parameters to [Transformer_model.pt]\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-137-373d273b66c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-127-b7914955bfbd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, clip_grad, max_epoch, max_patience, max_trial, lr_decay, train_batch_size, log_every, valid_niter)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Save currently the best model to [%s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# also save the optimizers' state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-123-7f81ae41708a>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       params = {\n\u001b[0;32m--> 118\u001b[0;31m           \u001b[0;34m'args'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m           \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m           \u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 539\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'EncoderDecoder' object has no attribute 'dropout_rate'"]}]},{"cell_type":"code","metadata":{"id":"aQnPjNLPA2q5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cb23d7d8-aef7-46b5-a3ec-67960ec6c5d8","executionInfo":{"status":"ok","timestamp":1559805783295,"user_tz":-480,"elapsed":810,"user":{"displayName":"Saun Walker","photoUrl":"https://lh3.googleusercontent.com/-pyhp3YfJmhI/AAAAAAAAAAI/AAAAAAAAAQk/B_Dez3ha7_M/s64/photo.jpg","userId":"15930704027125169268"}}},"source":["model.src_embed.reg_embed.LUT.weight.device"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"cFa9cRGjA2tR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oecKLEcPA2vp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJelnB92xBzw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4ziLpw-xChe","colab_type":"text"},"source":["## Beam Search"]},{"cell_type":"code","metadata":{"id":"jXLFK4X4A2yK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHu9Eg7CA20l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLXiyGLMA2ok","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkE29Q3wA2eG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}